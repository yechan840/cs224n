{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Do_a4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNu07u5HJTuuxTxptGNU8Cx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"laFNf_TP6q1o","executionInfo":{"status":"ok","timestamp":1627889767232,"user_tz":-540,"elapsed":1407,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"6562e424-0a69-44ad-d4a3-4e949f97871d"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where you have saved the unzipped\n","# 'cs231n' folder containing the '.py', 'classifiers' and 'datasets'\n","# folders.\n","# e.g. 'cs231n/assignments/assignment1/cs231n/'\n","FOLDERNAME = 'cs224n/assignment4/a4/'\n","\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","%cd drive/My\\ Drive\n","%cp -r $FOLDERNAME ../../\n","%cd ../../"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[Errno 2] No such file or directory: 'drive/My Drive'\n","/content/a4\n","cp: cannot stat 'cs224n/assignment4/a4/': No such file or directory\n","/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lhx7HP8SnAC3","executionInfo":{"status":"ok","timestamp":1627890445042,"user_tz":-540,"elapsed":524,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"c9f8c929-8692-4562-c985-1b20937c45bf"},"source":["%cd a4\n","!pwd"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'a4'\n","/\n","/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpcM4w8g7Elr","executionInfo":{"status":"ok","timestamp":1627885851287,"user_tz":-540,"elapsed":3598,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"c6de7980-d92e-4147-bc08-c8ad7b03db80"},"source":["!pip install sentencepiece"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 11.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSy2NYYD7EwQ","executionInfo":{"status":"ok","timestamp":1627885856640,"user_tz":-540,"elapsed":5357,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}}},"source":["import torch \n","import numpy as np\n","import scipy\n","import tqdm\n","import docopt\n","import nltk\n","import torchvision"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlUbtCen7E31","executionInfo":{"status":"ok","timestamp":1627885857264,"user_tz":-540,"elapsed":628,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"936e1f2c-32d6-40f0-ff8b-97add4e3bbb2"},"source":["# test problem (a), pad_sents in utils.py\n","from a4.utils import pad_sents \n","\n","sents = [\"I am a student\", \"I want my Olympic team to win\", \"My father is good at fixing\"]\n","sents = [s.split() for s in sents]\n","pad_token = \"<pad>\"\n","\n","pad_result = pad_sents(sents, pad_token)\n","for s in pad_result :\n","    print(\"%d : %s\"%(len(s), s))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","7 : ['I', 'am', 'a', 'student', '<pad>', '<pad>', '<pad>']\n","7 : ['I', 'want', 'my', 'Olympic', 'team', 'to', 'win']\n","7 : ['My', 'father', 'is', 'good', 'at', 'fixing', '<pad>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNHiR6Xp-XGF","executionInfo":{"status":"ok","timestamp":1627885859836,"user_tz":-540,"elapsed":2576,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"4d586d45-8005-4d7a-b8c9-9de1bd208d4d"},"source":["!python sanity_check.py 1d\n","# I don't know why but, using %run does not work properly even after fixing some bugs in nmt_model.py.\n","# It seems like that sanity_check already compiled with old-version of nmt_model and run it, although nmt_model.py has changed, I guess."],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Running Sanity Check for Question 1d: Encode\n","--------------------------------------------------------------------------------\n","enc_hiddens Sanity Checks Passed!\n","dec_init_state[0] Sanity Checks Passed!\n","dec_init_state[1] Sanity Checks Passed!\n","--------------------------------------------------------------------------------\n","All Sanity Checks Passed for Question 1d: Encode!\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHDm8NddmWbB","executionInfo":{"status":"ok","timestamp":1627887672895,"user_tz":-540,"elapsed":2141,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"f8ce6f36-7a3d-4ac0-887c-c3e55cdbb2fc"},"source":["!python sanity_check.py 1e"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","--------------------------------------------------------------------------------\n","Running Sanity Check for Question 1e: Decode\n","--------------------------------------------------------------------------------\n","torch.Size([23, 5, 3])\n","combined_outputs Sanity Checks Passed!\n","--------------------------------------------------------------------------------\n","All Sanity Checks Passed for Question 1e: Decode!\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1xeFuCNmWoD","executionInfo":{"status":"ok","timestamp":1627891507043,"user_tz":-540,"elapsed":2210,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"8385a75f-d6e5-40c1-f8ee-9c21470dffda"},"source":["!python sanity_check.py 1f"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","--------------------------------------------------------------------------------\n","Running Sanity Check for Question 1f: Step\n","--------------------------------------------------------------------------------\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","dec_state[0] Sanity Checks Passed!\n","dec_state[1] Sanity Checks Passed!\n","combined_output  Sanity Checks Passed!\n","e_t Sanity Checks Passed!\n","--------------------------------------------------------------------------------\n","All Sanity Checks Passed for Question 1f: Step!\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o038m1eN5ZUo"},"source":["Answer of (g) problem  \n","Attention scores in pad position are set to negative infinity. Therefore, after applying softmax, alpha_t in that position will be almost zero. Hence, a hidden state out of original sentence, which is not padded, does not contribute to context vector, i.e. a_t  \n","This is necessary because a hidden state of padding token is meaningless."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoMxqnAh5vSC","executionInfo":{"status":"ok","timestamp":1627891635623,"user_tz":-540,"elapsed":3694,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"e7796333-062b-42df-ba28-069f5a83681f"},"source":["!pip install sacrebleu"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Collecting sacrebleu\n","  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n","\u001b[?25l\r\u001b[K     |██████                          | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n","\u001b[?25hCollecting portalocker==2.0.0\n","  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: portalocker, sacrebleu\n","Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SQkevCcmW0J","executionInfo":{"status":"ok","timestamp":1627893489401,"user_tz":-540,"elapsed":617193,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"1de99164-74ee-47d6-ff89-38d5d10cf5b0"},"source":["!sh run.sh vocab\n","!sh run.sh train \n","\n","# My running time is 44min, with GPU runtime"],"execution_count":36,"outputs":[{"output_type":"stream","text":["epoch 4, iter 1850, avg. loss 64.36, avg. ppl 11.34 cum. examples 1600, speed 1319.29 words/sec, time elapsed 1217.42 sec\n","epoch 4, iter 1860, avg. loss 64.44, avg. ppl 11.25 cum. examples 1895, speed 1361.95 words/sec, time elapsed 1223.19 sec\n","epoch 5, iter 1870, avg. loss 58.85, avg. ppl 8.92 cum. examples 2215, speed 1385.93 words/sec, time elapsed 1229.40 sec\n","epoch 5, iter 1880, avg. loss 55.09, avg. ppl 8.22 cum. examples 2535, speed 1368.36 words/sec, time elapsed 1235.52 sec\n","epoch 5, iter 1890, avg. loss 55.39, avg. ppl 8.06 cum. examples 2855, speed 1338.65 words/sec, time elapsed 1241.86 sec\n","epoch 5, iter 1900, avg. loss 55.70, avg. ppl 8.20 cum. examples 3175, speed 1470.25 words/sec, time elapsed 1247.62 sec\n","epoch 5, iter 1910, avg. loss 52.64, avg. ppl 7.89 cum. examples 3495, speed 1388.71 words/sec, time elapsed 1253.50 sec\n","epoch 5, iter 1920, avg. loss 60.35, avg. ppl 9.50 cum. examples 3815, speed 1268.86 words/sec, time elapsed 1260.26 sec\n","epoch 5, iter 1930, avg. loss 51.42, avg. ppl 7.70 cum. examples 4135, speed 1448.33 words/sec, time elapsed 1265.82 sec\n","epoch 5, iter 1940, avg. loss 55.85, avg. ppl 8.55 cum. examples 4455, speed 1199.79 words/sec, time elapsed 1272.77 sec\n","epoch 5, iter 1950, avg. loss 57.83, avg. ppl 8.65 cum. examples 4775, speed 1467.91 words/sec, time elapsed 1278.61 sec\n","epoch 5, iter 1960, avg. loss 55.13, avg. ppl 8.34 cum. examples 5095, speed 1342.95 words/sec, time elapsed 1284.80 sec\n","epoch 5, iter 1970, avg. loss 58.77, avg. ppl 8.60 cum. examples 5415, speed 1490.83 words/sec, time elapsed 1290.67 sec\n","epoch 5, iter 1980, avg. loss 56.45, avg. ppl 9.02 cum. examples 5735, speed 1291.17 words/sec, time elapsed 1297.03 sec\n","epoch 5, iter 1990, avg. loss 60.20, avg. ppl 9.41 cum. examples 6055, speed 1284.96 words/sec, time elapsed 1303.71 sec\n","epoch 5, iter 2000, avg. loss 56.18, avg. ppl 8.70 cum. examples 6375, speed 1333.00 words/sec, time elapsed 1309.95 sec\n","epoch 5, iter 2000, cum. loss 58.35, cum. ppl 9.19 cum. examples 6375\n","begin validation ...\n","validation: iter 2000, dev. ppl 39.880652\n","hit patience 1\n","hit #2 trial\n","load previously best model and decay learning rate to 0.000125\n","restore parameters of the optimizers\n","epoch 5, iter 2010, avg. loss 54.48, avg. ppl 8.93 cum. examples 320, speed 738.26 words/sec, time elapsed 1320.73 sec\n","epoch 5, iter 2020, avg. loss 61.98, avg. ppl 10.69 cum. examples 640, speed 1136.66 words/sec, time elapsed 1328.10 sec\n","epoch 5, iter 2030, avg. loss 58.51, avg. ppl 9.71 cum. examples 960, speed 1179.43 words/sec, time elapsed 1335.08 sec\n","epoch 5, iter 2040, avg. loss 57.41, avg. ppl 9.22 cum. examples 1280, speed 1349.40 words/sec, time elapsed 1341.21 sec\n","epoch 5, iter 2050, avg. loss 54.22, avg. ppl 8.21 cum. examples 1600, speed 1450.71 words/sec, time elapsed 1346.89 sec\n","epoch 5, iter 2060, avg. loss 55.65, avg. ppl 8.66 cum. examples 1920, speed 1410.04 words/sec, time elapsed 1352.74 sec\n","epoch 5, iter 2070, avg. loss 53.73, avg. ppl 8.40 cum. examples 2240, speed 1361.56 words/sec, time elapsed 1358.68 sec\n","epoch 5, iter 2080, avg. loss 57.22, avg. ppl 9.00 cum. examples 2560, speed 1366.57 words/sec, time elapsed 1364.78 sec\n","epoch 5, iter 2090, avg. loss 57.14, avg. ppl 8.51 cum. examples 2880, speed 1416.81 words/sec, time elapsed 1370.81 sec\n","epoch 5, iter 2100, avg. loss 56.31, avg. ppl 8.65 cum. examples 3200, speed 1309.32 words/sec, time elapsed 1377.19 sec\n","epoch 5, iter 2110, avg. loss 56.87, avg. ppl 8.58 cum. examples 3520, speed 1397.33 words/sec, time elapsed 1383.24 sec\n","epoch 5, iter 2120, avg. loss 57.04, avg. ppl 9.38 cum. examples 3840, speed 1244.52 words/sec, time elapsed 1389.80 sec\n","epoch 5, iter 2130, avg. loss 55.89, avg. ppl 9.19 cum. examples 4160, speed 1337.19 words/sec, time elapsed 1395.82 sec\n","epoch 5, iter 2140, avg. loss 56.57, avg. ppl 9.32 cum. examples 4480, speed 1219.21 words/sec, time elapsed 1402.48 sec\n","epoch 5, iter 2150, avg. loss 54.97, avg. ppl 8.09 cum. examples 4800, speed 1416.09 words/sec, time elapsed 1408.42 sec\n","epoch 5, iter 2160, avg. loss 55.22, avg. ppl 8.38 cum. examples 5120, speed 1332.92 words/sec, time elapsed 1414.65 sec\n","epoch 5, iter 2170, avg. loss 61.50, avg. ppl 9.37 cum. examples 5440, speed 1049.71 words/sec, time elapsed 1423.03 sec\n","epoch 5, iter 2180, avg. loss 54.22, avg. ppl 7.74 cum. examples 5760, speed 1397.05 words/sec, time elapsed 1429.10 sec\n","epoch 5, iter 2190, avg. loss 56.14, avg. ppl 8.63 cum. examples 6080, speed 1306.62 words/sec, time elapsed 1435.48 sec\n","epoch 5, iter 2200, avg. loss 62.84, avg. ppl 9.92 cum. examples 6400, speed 1374.87 words/sec, time elapsed 1441.86 sec\n","epoch 5, iter 2200, cum. loss 56.90, cum. ppl 8.90 cum. examples 6400\n","begin validation ...\n","validation: iter 2200, dev. ppl 39.341908\n","hit patience 1\n","hit #3 trial\n","load previously best model and decay learning rate to 0.000063\n","restore parameters of the optimizers\n","epoch 5, iter 2210, avg. loss 57.51, avg. ppl 9.40 cum. examples 320, speed 726.51 words/sec, time elapsed 1453.16 sec\n","epoch 5, iter 2220, avg. loss 59.65, avg. ppl 9.69 cum. examples 640, speed 1364.55 words/sec, time elapsed 1459.32 sec\n","epoch 5, iter 2230, avg. loss 53.78, avg. ppl 8.21 cum. examples 960, speed 1371.12 words/sec, time elapsed 1465.28 sec\n","epoch 5, iter 2240, avg. loss 55.64, avg. ppl 8.47 cum. examples 1280, speed 1484.37 words/sec, time elapsed 1470.90 sec\n","epoch 5, iter 2250, avg. loss 57.81, avg. ppl 8.91 cum. examples 1600, speed 1395.71 words/sec, time elapsed 1476.96 sec\n","epoch 5, iter 2260, avg. loss 56.05, avg. ppl 9.10 cum. examples 1920, speed 1316.96 words/sec, time elapsed 1483.12 sec\n","epoch 5, iter 2270, avg. loss 58.26, avg. ppl 8.90 cum. examples 2240, speed 1380.46 words/sec, time elapsed 1489.30 sec\n","epoch 5, iter 2280, avg. loss 58.90, avg. ppl 8.78 cum. examples 2560, speed 1438.02 words/sec, time elapsed 1495.34 sec\n","epoch 5, iter 2290, avg. loss 57.55, avg. ppl 8.59 cum. examples 2880, speed 1406.38 words/sec, time elapsed 1501.42 sec\n","epoch 5, iter 2300, avg. loss 58.15, avg. ppl 9.07 cum. examples 3200, speed 1352.91 words/sec, time elapsed 1507.66 sec\n","epoch 5, iter 2310, avg. loss 56.14, avg. ppl 8.76 cum. examples 3520, speed 1401.89 words/sec, time elapsed 1513.57 sec\n","epoch 5, iter 2320, avg. loss 53.18, avg. ppl 8.27 cum. examples 3840, speed 1375.08 words/sec, time elapsed 1519.42 sec\n","epoch 6, iter 2330, avg. loss 53.67, avg. ppl 8.52 cum. examples 4135, speed 1336.33 words/sec, time elapsed 1524.95 sec\n","epoch 6, iter 2340, avg. loss 54.01, avg. ppl 8.39 cum. examples 4455, speed 1362.22 words/sec, time elapsed 1530.92 sec\n","epoch 6, iter 2350, avg. loss 58.69, avg. ppl 8.83 cum. examples 4775, speed 1305.74 words/sec, time elapsed 1537.52 sec\n","epoch 6, iter 2360, avg. loss 55.48, avg. ppl 8.55 cum. examples 5095, speed 1270.10 words/sec, time elapsed 1544.03 sec\n","epoch 6, iter 2370, avg. loss 51.24, avg. ppl 8.01 cum. examples 5415, speed 1414.77 words/sec, time elapsed 1549.60 sec\n","epoch 6, iter 2380, avg. loss 50.40, avg. ppl 7.41 cum. examples 5735, speed 1461.97 words/sec, time elapsed 1555.11 sec\n","epoch 6, iter 2390, avg. loss 51.61, avg. ppl 7.75 cum. examples 6055, speed 1331.51 words/sec, time elapsed 1561.17 sec\n","epoch 6, iter 2400, avg. loss 56.65, avg. ppl 8.09 cum. examples 6375, speed 1377.49 words/sec, time elapsed 1567.46 sec\n","epoch 6, iter 2400, cum. loss 55.73, cum. ppl 8.58 cum. examples 6375\n","begin validation ...\n","validation: iter 2400, dev. ppl 39.305610\n","hit patience 1\n","hit #4 trial\n","load previously best model and decay learning rate to 0.000031\n","restore parameters of the optimizers\n","epoch 6, iter 2410, avg. loss 58.81, avg. ppl 8.72 cum. examples 320, speed 788.18 words/sec, time elapsed 1578.49 sec\n","epoch 6, iter 2420, avg. loss 56.08, avg. ppl 8.81 cum. examples 640, speed 1340.61 words/sec, time elapsed 1584.64 sec\n","epoch 6, iter 2430, avg. loss 58.46, avg. ppl 9.22 cum. examples 960, speed 1423.18 words/sec, time elapsed 1590.56 sec\n","epoch 6, iter 2440, avg. loss 58.13, avg. ppl 9.15 cum. examples 1280, speed 1459.28 words/sec, time elapsed 1596.31 sec\n","epoch 6, iter 2450, avg. loss 58.88, avg. ppl 9.07 cum. examples 1600, speed 1294.28 words/sec, time elapsed 1602.92 sec\n","epoch 6, iter 2460, avg. loss 56.62, avg. ppl 8.36 cum. examples 1920, speed 1421.18 words/sec, time elapsed 1608.92 sec\n","epoch 6, iter 2470, avg. loss 58.04, avg. ppl 8.84 cum. examples 2240, speed 1518.96 words/sec, time elapsed 1614.53 sec\n","epoch 6, iter 2480, avg. loss 54.60, avg. ppl 8.49 cum. examples 2560, speed 1436.32 words/sec, time elapsed 1620.21 sec\n","epoch 6, iter 2490, avg. loss 60.17, avg. ppl 9.65 cum. examples 2880, speed 1318.13 words/sec, time elapsed 1626.66 sec\n","epoch 6, iter 2500, avg. loss 64.44, avg. ppl 9.32 cum. examples 3200, speed 1352.47 words/sec, time elapsed 1633.49 sec\n","epoch 6, iter 2510, avg. loss 56.90, avg. ppl 8.79 cum. examples 3520, speed 1380.40 words/sec, time elapsed 1639.56 sec\n","epoch 6, iter 2520, avg. loss 55.02, avg. ppl 8.30 cum. examples 3840, speed 1378.46 words/sec, time elapsed 1645.59 sec\n","epoch 6, iter 2530, avg. loss 59.35, avg. ppl 9.23 cum. examples 4160, speed 1266.87 words/sec, time elapsed 1652.34 sec\n","epoch 6, iter 2540, avg. loss 59.09, avg. ppl 8.73 cum. examples 4480, speed 1369.16 words/sec, time elapsed 1658.71 sec\n","epoch 6, iter 2550, avg. loss 58.63, avg. ppl 9.46 cum. examples 4800, speed 1294.70 words/sec, time elapsed 1665.16 sec\n","epoch 6, iter 2560, avg. loss 51.58, avg. ppl 8.11 cum. examples 5120, speed 1278.59 words/sec, time elapsed 1671.33 sec\n","epoch 6, iter 2570, avg. loss 61.71, avg. ppl 9.62 cum. examples 5440, speed 1268.11 words/sec, time elapsed 1678.20 sec\n","epoch 6, iter 2580, avg. loss 59.51, avg. ppl 9.33 cum. examples 5760, speed 1190.60 words/sec, time elapsed 1685.37 sec\n","epoch 6, iter 2590, avg. loss 59.18, avg. ppl 9.82 cum. examples 6080, speed 1350.84 words/sec, time elapsed 1691.50 sec\n","epoch 6, iter 2600, avg. loss 60.61, avg. ppl 9.16 cum. examples 6400, speed 1270.01 words/sec, time elapsed 1698.40 sec\n","epoch 6, iter 2600, cum. loss 58.29, cum. ppl 9.00 cum. examples 6400\n","begin validation ...\n","validation: iter 2600, dev. ppl 38.888811\n","save currently the best model to [model.bin]\n","save model parameters to [model.bin]\n","epoch 6, iter 2610, avg. loss 56.25, avg. ppl 8.40 cum. examples 320, speed 594.56 words/sec, time elapsed 1712.62 sec\n","epoch 6, iter 2620, avg. loss 56.20, avg. ppl 9.29 cum. examples 640, speed 1420.81 words/sec, time elapsed 1718.30 sec\n","epoch 6, iter 2630, avg. loss 54.32, avg. ppl 8.44 cum. examples 960, speed 1345.38 words/sec, time elapsed 1724.36 sec\n","epoch 6, iter 2640, avg. loss 53.84, avg. ppl 8.54 cum. examples 1280, speed 1330.01 words/sec, time elapsed 1730.40 sec\n","epoch 6, iter 2650, avg. loss 58.38, avg. ppl 8.78 cum. examples 1600, speed 1363.37 words/sec, time elapsed 1736.71 sec\n","epoch 6, iter 2660, avg. loss 54.07, avg. ppl 8.31 cum. examples 1920, speed 1361.59 words/sec, time elapsed 1742.71 sec\n","epoch 6, iter 2670, avg. loss 54.99, avg. ppl 8.05 cum. examples 2240, speed 1441.77 words/sec, time elapsed 1748.56 sec\n","epoch 6, iter 2680, avg. loss 54.48, avg. ppl 8.60 cum. examples 2560, speed 1306.45 words/sec, time elapsed 1754.76 sec\n","epoch 6, iter 2690, avg. loss 57.08, avg. ppl 9.30 cum. examples 2880, speed 1293.47 words/sec, time elapsed 1761.10 sec\n","epoch 6, iter 2700, avg. loss 51.94, avg. ppl 8.07 cum. examples 3200, speed 1392.44 words/sec, time elapsed 1766.81 sec\n","epoch 6, iter 2710, avg. loss 53.53, avg. ppl 7.90 cum. examples 3520, speed 1334.95 words/sec, time elapsed 1773.02 sec\n","epoch 6, iter 2720, avg. loss 51.85, avg. ppl 8.30 cum. examples 3840, speed 1304.48 words/sec, time elapsed 1779.03 sec\n","epoch 6, iter 2730, avg. loss 53.73, avg. ppl 8.10 cum. examples 4160, speed 1342.27 words/sec, time elapsed 1785.15 sec\n","epoch 6, iter 2740, avg. loss 56.50, avg. ppl 8.95 cum. examples 4480, speed 1376.93 words/sec, time elapsed 1791.15 sec\n","epoch 6, iter 2750, avg. loss 59.48, avg. ppl 9.39 cum. examples 4800, speed 1197.32 words/sec, time elapsed 1798.24 sec\n","epoch 6, iter 2760, avg. loss 54.44, avg. ppl 8.52 cum. examples 5120, speed 1421.56 words/sec, time elapsed 1803.97 sec\n","epoch 6, iter 2770, avg. loss 59.45, avg. ppl 9.06 cum. examples 5440, speed 1401.76 words/sec, time elapsed 1810.12 sec\n","epoch 6, iter 2780, avg. loss 57.65, avg. ppl 8.57 cum. examples 5760, speed 1215.19 words/sec, time elapsed 1817.19 sec\n","epoch 6, iter 2790, avg. loss 57.12, avg. ppl 8.46 cum. examples 6055, speed 1319.21 words/sec, time elapsed 1823.17 sec\n","epoch 7, iter 2800, avg. loss 54.13, avg. ppl 7.98 cum. examples 6375, speed 1344.93 words/sec, time elapsed 1829.37 sec\n","epoch 7, iter 2800, cum. loss 55.46, cum. ppl 8.54 cum. examples 6375\n","begin validation ...\n","validation: iter 2800, dev. ppl 39.008023\n","hit patience 1\n","hit #5 trial\n","early stop!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJPMqmCdrthO","executionInfo":{"status":"ok","timestamp":1627894442732,"user_tz":-540,"elapsed":121921,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"5cd10634-038f-4ff2-ce9b-d4bfbb5ac1d7"},"source":["# problem (h)\n","!sh run.sh test\n","# my score is 12.40"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","load test source sentences from [./chr_en_data/test.chr]\n","load test target sentences from [./chr_en_data/test.en]\n","load model from model.bin\n","Decoding:   0% 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","Decoding: 100% 1000/1000 [01:54<00:00,  8.70it/s]\n","Corpus BLEU: 12.403887429414992\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uA4pe0VF6C02"},"source":["Problem (i)  \n","One advantage of dot product is computationally less expensive. One disadvantage is attention score is simmilary, therefore context vector is simmilar to hidden state of decoder.  \n","One advantage of additive attention is that it has more parameters to be leanred.  One disadvantage is computationally expensive. "]},{"cell_type":"code","metadata":{"id":"vL0GRNRP503V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nb-G3LqT51CT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"gFBIz9qs6-b3","executionInfo":{"status":"error","timestamp":1627896398691,"user_tz":-540,"elapsed":322533,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}},"outputId":"1ccf5959-7236-4881-d28b-a233f3b09fe2"},"source":["import os\n","import time\n","\n","# Keep my runtime from shut down by Google when I write python files \n","# Because I do not run and fix Jupyter file, it terminates \n","\n","def save_files() :\n","    FILES_TO_SAVE = ['utils.py', 'model_embeddings.py', 'nmt_model.py', 'outputs/test_outputs.txt']\n","    FOLDER_TO_SAVE = os.path.join('../drive/My Drive/', FOLDERNAME)\n","\n","    for files in FILES_TO_SAVE:\n","        with open(os.path.join(FOLDER_TO_SAVE, '/'.join(files.split('/'))), 'w') as f:\n","            f.write(''.join(open(files).readlines()))\n","\n","for i in range(10) :\n","    save_files()\n","    time.sleep(300)"],"execution_count":41,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-ddea0349b40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msave_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"iep3lWNGEFaN","executionInfo":{"status":"ok","timestamp":1627891521464,"user_tz":-540,"elapsed":345,"user":{"displayName":"이예찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0com__kaN-l0ZTP1S1xb9T___Zo0w2E4xrI3V=s64","userId":"08218161544126837732"}}},"source":["save_files()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jdfV08D8ERB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M854vGQU8FN7"},"source":["Problem (a)  \n","A polysynthetic language is a language whose single words many express the meaning of whole phrases or clauses. (From Collins English Dictionary 30th Anniversary Edition) Therefore, one word of Cherokee might be too big unit of meaning."]},{"cell_type":"markdown","metadata":{"id":"VJN_mkNf9AYB"},"source":["Problem (b)  \n","It is because every word is compound of characters or subwords. Therefore, the number of word is higher than that of characters and subwords."]},{"cell_type":"markdown","metadata":{"id":"JQSaGlfc9BVc"},"source":["Problem (c)  \n","It captures universal commonality across languages and uses it to scare languages. "]},{"cell_type":"markdown","metadata":{"id":"kaMuyW2N9pWL"},"source":["Problem (d)  \n","(i) It is about wrong alignment. Therefore, we need more parameters in attention mechanism  \n","(ii) Wrong choice of word. It needs more hidden layers  \n","(iii) I think that it is because \"Littlefish\" is not in the vocabulary. It needs larger vocabulary  \n","\n","I'm a foriegn. Unforunately, I know neither English nor Cherokee. OMG"]},{"cell_type":"markdown","metadata":{"id":"pZZ2WnQk9peO"},"source":["Problem (e)  \n"]},{"cell_type":"markdown","metadata":{"id":"vopxM-mp9piq"},"source":["Problem (f)  "]},{"cell_type":"code","metadata":{"id":"NkiUC-O38_bk"},"source":[""],"execution_count":null,"outputs":[]}]}